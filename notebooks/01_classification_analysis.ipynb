{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Analysis: MAGIC Gamma Telescope\n",
        "## Problem Statement 1 - Complete Implementation\n",
        "\n",
        "**Student:** [Your Name]  \n",
        "**Course:** Introduction to Machine Learning  \n",
        "**Date:** [Current Date]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction\n",
        "\n",
        "This notebook implements K-Nearest Neighbors (K-NN) classification for the MAGIC Gamma Telescope dataset to distinguish between gamma particles (signal) and hadrons (background)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../src')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MAGIC dataset\n",
        "file_path = \"../data/magic_gamma_telescope/magic04.data\"\n",
        "column_names = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
        "data = pd.read_csv(file_path, names=column_names)\n",
        "\n",
        "print(\"üìä MAGIC GAMMA TELESCOPE DATASET\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Dataset shape: {data.shape}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(data['class'].value_counts())\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance the dataset\n",
        "class_g = data[data['class'] == 'g']\n",
        "class_h = data[data['class'] == 'h']\n",
        "\n",
        "min_size = min(len(class_g), len(class_h))\n",
        "class_g_balanced = class_g.sample(min_size, random_state=42)\n",
        "class_h_balanced = class_h.sample(min_size, random_state=42)\n",
        "\n",
        "balanced_data = pd.concat([class_g_balanced, class_h_balanced])\n",
        "\n",
        "print(\"üîß DATA BALANCING\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original sizes - Gamma: {len(class_g)}, Hadron: {len(class_h)}\")\n",
        "print(f\"Balanced sizes - Gamma: {len(class_g_balanced)}, Hadron: {len(class_h_balanced)}\")\n",
        "print(f\"\\nBalanced class distribution:\")\n",
        "print(balanced_data['class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Manual K-NN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ManualKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "    \n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict_single(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def _predict_single(self, x):\n",
        "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        most_common = np.bincount(k_nearest_labels).argmax()\n",
        "        return most_common\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return np.mean(predictions == y)\n",
        "\n",
        "print(\"‚úÖ Manual K-NN class defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "X = balanced_data.drop('class', axis=1).values\n",
        "y = balanced_data['class'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split data (70% train, 15% validation, 15% test)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"üìä DATA SPLITTING RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. K Value Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different k values\n",
        "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
        "manual_val_accuracies = []\n",
        "sklearn_val_accuracies = []\n",
        "\n",
        "print(\"üîç K VALUE TUNING - MANUAL K-NN\")\n",
        "print(\"=\" * 40)\n",
        "for k in k_values:\n",
        "    knn_manual = ManualKNN(k=k)\n",
        "    knn_manual.fit(X_train_scaled, y_train)\n",
        "    val_acc = knn_manual.score(X_val_scaled, y_val)\n",
        "    manual_val_accuracies.append(val_acc)\n",
        "    print(f\"k={k}: Validation Accuracy = {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nüîç K VALUE TUNING - SCIKIT-LEARN K-NN\")\n",
        "print(\"=\" * 45)\n",
        "for k in k_values:\n",
        "    knn_sklearn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_sklearn.fit(X_train_scaled, y_train)\n",
        "    val_acc = knn_sklearn.score(X_val_scaled, y_val)\n",
        "    sklearn_val_accuracies.append(val_acc)\n",
        "    print(f\"k={k}: Validation Accuracy = {val_acc:.4f}\")\n",
        "\n",
        "# Find best k values\n",
        "best_k_manual = k_values[np.argmax(manual_val_accuracies)]\n",
        "best_k_sklearn = k_values[np.argmax(sklearn_val_accuracies)]\n",
        "print(f\"\\n‚úÖ Best k - Manual: {best_k_manual}, Scikit-Learn: {best_k_sklearn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot validation accuracy vs k values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(k_values, manual_val_accuracies, 'bo-', label='Manual K-NN', linewidth=2, markersize=8)\n",
        "plt.plot(k_values, sklearn_val_accuracies, 'ro-', label='Scikit-Learn K-NN', linewidth=2, markersize=8)\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('K-NN: Validation Accuracy vs K Value')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(k_values)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Final Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final models with best k\n",
        "final_manual_knn = ManualKNN(k=best_k_manual)\n",
        "final_manual_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "final_sklearn_knn = KNeighborsClassifier(n_neighbors=best_k_sklearn)\n",
        "final_sklearn_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_manual = final_manual_knn.predict(X_test_scaled)\n",
        "y_pred_sklearn = final_sklearn_knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation metrics\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\nüìä {model_name} RESULTS\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "    \n",
        "    return accuracy, precision, recall, f1, cm\n",
        "\n",
        "manual_metrics = evaluate_model(y_test, y_pred_manual, \"MANUAL K-NN\")\n",
        "sklearn_metrics = evaluate_model(y_test, y_pred_sklearn, \"SCIKIT-LEARN K-NN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Key Findings and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç KEY FINDINGS AND INSIGHTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\n1. OPTIMAL K VALUE:\")\n",
        "print(f\"   ‚Ä¢ Manual K-NN: k={best_k_manual}\")\n",
        "print(f\"   ‚Ä¢ Scikit-Learn K-NN: k={best_k_sklearn}\")\n",
        "\n",
        "print(f\"\\n2. MODEL PERFORMANCE:\")\n",
        "print(f\"   ‚Ä¢ Best Accuracy: {max(manual_metrics[0], sklearn_metrics[0]):.4f}\")\n",
        "print(f\"   ‚Ä¢ Manual vs Scikit-Learn difference: {abs(manual_metrics[0] - sklearn_metrics[0]):.6f}\")\n",
        "\n",
        "print(f\"\\n3. IMPLEMENTATION VALIDATION:\")\n",
        "difference = abs(manual_metrics[0] - sklearn_metrics[0])\n",
        "if difference < 0.01:\n",
        "    print(f\"   ‚Ä¢ ‚úÖ EXCELLENT: Manual implementation matches scikit-learn!\")\n",
        "elif difference < 0.05:\n",
        "    print(f\"   ‚Ä¢ ‚úÖ GOOD: Manual implementation is very close to scikit-learn!\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ ‚ö†Ô∏è  ACCEPTABLE: Some difference between implementations\")\n",
        "\n",
        "print(f\"\\n4. DATASET CHARACTERISTICS:\")\n",
        "print(f\"   ‚Ä¢ Balanced dataset: {len(balanced_data)} samples\")\n",
        "print(f\"   ‚Ä¢ Features: {X.shape[1]}\")\n",
        "print(f\"   ‚Ä¢ Classes: Gamma vs Hadron\")\n",
        "\n",
        "print(f\"\\n‚úÖ CLASSIFICATION ANALYSIS COMPLETED SUCCESSFULLY!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}